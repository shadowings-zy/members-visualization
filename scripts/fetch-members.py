#!/usr/bin/env python3
"""
æ•°æ®æ‹‰å–è„šæœ¬ (Python ç‰ˆæœ¬)
ä» GitHub API è·å–ç»„ç»‡æˆå‘˜ä¿¡æ¯å¹¶è½¬æ¢ä¸º CSV æ ¼å¼
"""

import os
import sys
import csv
import json
import time
try:
    import requests
except ImportError:
    requests = None
from pathlib import Path

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # python-dotenv ä¸æ˜¯å¿…éœ€çš„ï¼Œå¦‚æœæ²¡æœ‰å®‰è£…å°±å¿½ç•¥
    pass

# é…ç½®
CONFIG = {
    'ORG_NAME': os.getenv('GITHUB_ORG', 'datawhalechina'),
    'GITHUB_TOKEN': os.getenv('GITHUB_TOKEN'),
    'OUTPUT_FILE': Path(__file__).parent.parent / 'data' / 'members.csv',
    'AVATARS_DIR': Path(__file__).parent.parent / 'docs' / 'public' / 'avatars',  # å¤´åƒç¼“å­˜ç›®å½•
    'API_BASE': 'https://api.github.com',
    'MIN_CONTRIBUTIONS': int(os.getenv('MIN_CONTRIBUTIONS', '10')),  # æœ€å°è´¡çŒ®è¡Œæ•°é˜ˆå€¼ï¼ˆé™ä½ä»¥åŒ…å«æ›´å¤šè´¡çŒ®è€…ï¼‰
    'MAX_REPOS_PER_PAGE': 100,  # æ¯é¡µæœ€å¤§ä»“åº“æ•°
    'MAX_CONTRIBUTORS_PER_REPO': 100,  # æ¯ä¸ªä»“åº“æœ€å¤§è´¡çŒ®è€…æ•°
    'MAX_USER_REPOS': 100,  # è·å–ç”¨æˆ·ä»“åº“çš„æœ€å¤§æ•°é‡
    'DEFAULT_DOMAINS': {
        'machine-learning': 'æœºå™¨å­¦ä¹ ',
        'deep-learning': 'æ·±åº¦å­¦ä¹ ',
        'nlp': 'NLP',
        'cv': 'CV',
        'data-mining': 'æ•°æ®æŒ–æ˜',
        'recommendation-system': 'æ¨èç³»ç»Ÿ',
        'reinforcement-learning': 'å¼ºåŒ–å­¦ä¹ ',
        'computer-vision': 'CV',
        'natural-language-processing': 'NLP',
        'artificial-intelligence': 'äººå·¥æ™ºèƒ½',
        'llm': 'LLM',
        'data-science': 'æ•°æ®ç§‘å­¦',
        'frontend': 'å‰ç«¯å¼€å‘',
        'backend': 'åç«¯å¼€å‘',
        'fullstack': 'å…¨æ ˆå¼€å‘'
    }
}

def get_headers():
    """è·å–è¯·æ±‚å¤´"""
    headers = {
        'User-Agent': 'members-visualization-bot',
        'Accept': 'application/vnd.github.v3+json'
    }
    
    if CONFIG['GITHUB_TOKEN']:
        headers['Authorization'] = f"Bearer {CONFIG['GITHUB_TOKEN']}"

    return headers

def fetch_api(url, retries=3):
    """å‘é€ API è¯·æ±‚ï¼ˆå¸¦é‡è¯•é€»è¾‘ï¼‰"""
    if not CONFIG['GITHUB_TOKEN']:
        print("âš ï¸  æœªè®¾ç½® GITHUB_TOKENï¼Œå¯èƒ½ä¼šé‡åˆ° API é€Ÿç‡é™åˆ¶")

    for attempt in range(retries):
        try:
            print(f"ğŸ”„ è¯·æ±‚ {url} (å°è¯• {attempt + 1}/{retries})")

            response = requests.get(url, headers=get_headers(), timeout=30)

            # æ£€æŸ¥é€Ÿç‡é™åˆ¶
            remaining = response.headers.get('X-RateLimit-Remaining')
            reset_time = response.headers.get('X-RateLimit-Reset')

            if remaining:
                print(f"ğŸ“Š API å‰©ä½™è¯·æ±‚æ¬¡æ•°: {remaining}")

            if response.status_code == 403 and remaining == '0':
                if reset_time and attempt < retries - 1:
                    reset_timestamp = int(reset_time)
                    wait_time = reset_timestamp - int(time.time()) + 1
                    if wait_time > 0:
                        print(f"â³ API é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                        continue
                raise requests.exceptions.HTTPError(f"API é€Ÿç‡é™åˆ¶å·²è¾¾ä¸Šé™")

            response.raise_for_status()
            return response.json()

        except requests.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {url}")
            print(f"é”™è¯¯: {e}")

            if attempt == retries - 1:
                return None

            # æŒ‡æ•°é€€é¿å»¶è¿Ÿ
            wait_time = (2 ** attempt)
            print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
            time.sleep(wait_time)

    return None

def get_org_repos(org_name):
    """è·å–ç»„ç»‡ä»“åº“åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
    print(f"æ­£åœ¨è·å–ç»„ç»‡ {org_name} çš„ä»“åº“åˆ—è¡¨...")

    all_repos = []
    page = 1
    per_page = CONFIG['MAX_REPOS_PER_PAGE']

    while True:
        url = f"{CONFIG['API_BASE']}/orgs/{org_name}/repos?per_page={per_page}&page={page}&type=public&sort=updated"
        repos = fetch_api(url)

        if not repos or len(repos) == 0:
            break

        # è¿‡æ»¤æ‰ fork çš„ä»“åº“ï¼Œåªä¿ç•™åŸåˆ›ä»“åº“
        original_repos = [repo for repo in repos if not repo.get('fork', False)]
        all_repos.extend(original_repos)

        print(f"è·å–ç¬¬ {page} é¡µï¼š{len(repos)} ä¸ªä»“åº“ï¼ˆ{len(original_repos)} ä¸ªåŸåˆ›ï¼‰")

        # å¦‚æœè¿”å›çš„ä»“åº“æ•°å°‘äºæ¯é¡µé™åˆ¶ï¼Œè¯´æ˜å·²ç»æ˜¯æœ€åä¸€é¡µ
        if len(repos) < per_page:
            break

        page += 1

        # å®‰å…¨é™åˆ¶ï¼šæœ€å¤šè·å–20é¡µï¼ˆ2000ä¸ªä»“åº“ï¼‰
        if page > 20:
            print("âš ï¸ è¾¾åˆ°é¡µæ•°é™åˆ¶ï¼Œåœæ­¢è·å–")
            break

    print(f"æ€»å…±æ‰¾åˆ° {len(all_repos)} ä¸ªåŸåˆ›ä»“åº“")
    return all_repos

def get_repo_contributors(owner, repo_name):
    """è·å–ä»“åº“è´¡çŒ®è€…åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
    all_contributors = []
    page = 1
    per_page = 100

    while True:
        url = f"{CONFIG['API_BASE']}/repos/{owner}/{repo_name}/contributors?per_page={per_page}&page={page}"
        contributors = fetch_api(url)

        if not contributors or len(contributors) == 0:
            break

        all_contributors.extend(contributors)

        # å¦‚æœè¿”å›çš„è´¡çŒ®è€…æ•°å°‘äºæ¯é¡µé™åˆ¶ï¼Œè¯´æ˜å·²ç»æ˜¯æœ€åä¸€é¡µ
        if len(contributors) < per_page:
            break

        page += 1

        # å®‰å…¨é™åˆ¶ï¼šæœ€å¤šè·å–10é¡µï¼ˆ1000ä¸ªè´¡çŒ®è€…ï¼‰
        if page > 10:
            print(f"    âš ï¸ ä»“åº“ {repo_name} è´¡çŒ®è€…è¿‡å¤šï¼Œå·²è¾¾é¡µæ•°é™åˆ¶")
            break

    # è¿‡æ»¤æ‰è´¡çŒ®æ•°ä½äºé˜ˆå€¼çš„è´¡çŒ®è€…
    qualified_contributors = []
    for contributor in all_contributors:
        contributions = contributor.get('contributions', 0)
        if contributions >= CONFIG['MIN_CONTRIBUTIONS']:
            qualified_contributors.append({
                'login': contributor['login'],
                'contributions': contributions,
                'html_url': contributor['html_url'],
                'avatar_url': contributor['avatar_url']
            })

    print(f"    ğŸ“Š æ€»è´¡çŒ®è€…: {len(all_contributors)}, ç¬¦åˆæ¡ä»¶(â‰¥{CONFIG['MIN_CONTRIBUTIONS']}è¡Œ): {len(qualified_contributors)}")
    return qualified_contributors

def collect_contributors_from_repos(org_name):
    """ä»ç»„ç»‡ä»“åº“ä¸­æ”¶é›†è´¡çŒ®è€…æ•°æ®"""
    print(f"ğŸš€ å¼€å§‹ä» {org_name} ç»„ç»‡ä»“åº“æ”¶é›†è´¡çŒ®è€…æ•°æ®...")

    # è·å–ç»„ç»‡æ‰€æœ‰ä»“åº“
    repos = get_org_repos(org_name)
    if not repos:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ä»“åº“")
        return {}

    contributors_data = {}  # {username: {repos: [repo_names], total_contributions: int, user_info: dict}}

    for i, repo in enumerate(repos):
        repo_name = repo['name']
        print(f"\nğŸ“ å¤„ç†ä»“åº“ {i + 1}/{len(repos)}: {repo_name}")

        try:
            # è·å–ä»“åº“è´¡çŒ®è€…
            contributors = get_repo_contributors(org_name, repo_name)
            print(f"  âœ“ æ‰¾åˆ° {len(contributors)} ä¸ªç¬¦åˆæ¡ä»¶çš„è´¡çŒ®è€…ï¼ˆâ‰¥{CONFIG['MIN_CONTRIBUTIONS']}è¡Œï¼‰")

            for contributor in contributors:
                username = contributor['login']
                contributions = contributor['contributions']

                if username not in contributors_data:
                    contributors_data[username] = {
                        'repos': [],
                        'total_contributions': 0,
                        'user_info': {
                            'html_url': contributor['html_url'],
                            'avatar_url': contributor['avatar_url']
                        }
                    }

                contributors_data[username]['repos'].append(repo_name)
                contributors_data[username]['total_contributions'] += contributions

            # API é€Ÿç‡é™åˆ¶æ§åˆ¶
            delay = 0.1 if CONFIG['GITHUB_TOKEN'] else 0.5
            time.sleep(delay)

        except Exception as e:
            print(f"  âš ï¸ å¤„ç†ä»“åº“ {repo_name} æ—¶å‡ºé”™: {e}")
            continue

    print(f"\nğŸ‰ æ”¶é›†å®Œæˆï¼æ€»å…±å‘ç° {len(contributors_data)} ä¸ªè´¡çŒ®è€…")
    return contributors_data

def download_avatar(avatar_url, username):
    """ä¸‹è½½å¹¶ç¼“å­˜ç”¨æˆ·å¤´åƒ"""
    if not avatar_url or not requests:
        return None

    # ç¡®ä¿å¤´åƒç›®å½•å­˜åœ¨
    CONFIG['AVATARS_DIR'].mkdir(parents=True, exist_ok=True)

    # å¤´åƒæ–‡ä»¶è·¯å¾„
    avatar_filename = f"{username}.jpg"
    avatar_path = CONFIG['AVATARS_DIR'] / avatar_filename

    # å¦‚æœå¤´åƒå·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›ç›¸å¯¹è·¯å¾„
    if avatar_path.exists():
        return f"avatars/{avatar_filename}"

    try:
        print(f"  ğŸ“¸ ä¸‹è½½å¤´åƒ: {username}")
        response = requests.get(avatar_url, timeout=30)
        response.raise_for_status()

        with open(avatar_path, 'wb') as f:
            f.write(response.content)

        return f"avatars/{avatar_filename}"
    except Exception as e:
        print(f"  âš ï¸ å¤´åƒä¸‹è½½å¤±è´¥ {username}: {e}")
        return None

def get_user_details(username):
    """è·å–ç”¨æˆ·è¯¦ç»†ä¿¡æ¯"""
    url = f"{CONFIG['API_BASE']}/users/{username}"
    return fetch_api(url)

def get_user_repos(username, max_repos=None):
    """è·å–ç”¨æˆ·ä»“åº“ä¿¡æ¯"""
    if max_repos is None:
        max_repos = CONFIG['MAX_USER_REPOS']

    url = f"{CONFIG['API_BASE']}/users/{username}/repos?sort=updated&per_page={max_repos}"
    repos = fetch_api(url)
    return repos if repos else []

def calculate_user_stats(user_details, user_repos):
    """è®¡ç®—ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯"""
    if not user_details:
        return {
            'public_repos': 0,
            'total_stars': 0,
            'followers': 0,
            'following': 0
        }

    # ä»ç”¨æˆ·è¯¦æƒ…è·å–åŸºæœ¬ç»Ÿè®¡
    stats = {
        'public_repos': user_details.get('public_repos', 0),
        'followers': user_details.get('followers', 0),
        'following': user_details.get('following', 0),
        'total_stars': 0
    }

    # è®¡ç®—æ€» Starsï¼ˆä»ç”¨æˆ·ä»“åº“ä¸­ç´¯åŠ ï¼‰
    if user_repos:
        stats['total_stars'] = sum(repo.get('stargazers_count', 0) for repo in user_repos)

    return stats

def infer_domains_from_repos(repo_names, user_bio='', user_repos=None):
    """æ ¹æ®ä»“åº“ topicsã€åç§°å’Œç”¨æˆ·ç®€ä»‹æ¨æ–­ç ”ç©¶æ–¹å‘"""
    domains = set()

    # ä»ç”¨æˆ·ç®€ä»‹ä¸­æå–å…³é”®è¯
    text = (user_bio or '').lower()
    for key, value in CONFIG['DEFAULT_DOMAINS'].items():
        if key in text or value.lower() in text:
            domains.add(value)

    # æ”¶é›†æ‰€æœ‰ä»“åº“çš„ topics
    all_topics = []
    if user_repos:
        for repo in user_repos:
            if isinstance(repo, dict) and 'topics' in repo:
                topics = repo.get('topics', [])
                if topics:
                    all_topics.extend(topics)

    # ä»ä»“åº“ topics ä¸­æå–å…³é”®è¯ï¼ˆä¼˜å…ˆä½¿ç”¨ topicsï¼‰
    topics_text = ' '.join(all_topics).lower()
    for key, value in CONFIG['DEFAULT_DOMAINS'].items():
        if key in topics_text or value.lower() in topics_text:
            domains.add(value)

    # å¦‚æœ topics ä¸­æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿä¿¡æ¯ï¼Œå†ä»ä»“åº“åç§°ä¸­æå–å…³é”®è¯ä½œä¸ºè¡¥å……
    repo_text = ' '.join(repo_names).lower()
    for key, value in CONFIG['DEFAULT_DOMAINS'].items():
        if key in repo_text or value.lower() in repo_text:
            domains.add(value)

    # æ ¹æ® topics å’Œä»“åº“åç§°çš„å¸¸è§æ¨¡å¼æ¨æ–­ï¼ˆä¼˜å…ˆä½¿ç”¨ topicsï¼‰
    search_text = topics_text if topics_text.strip() else repo_text

    if any(keyword in search_text for keyword in ['ml', 'machine-learning', 'sklearn']):
        domains.add('æœºå™¨å­¦ä¹ ')
    if any(keyword in search_text for keyword in ['dl', 'deep-learning', 'pytorch', 'tensorflow']):
        domains.add('æ·±åº¦å­¦ä¹ ')
    if any(keyword in search_text for keyword in ['nlp', 'natural-language', 'bert', 'transformer']):
        domains.add('NLP')
    if any(keyword in search_text for keyword in ['recommendation', 'recommendation-system', 'ctr-prediction', 'recommender-system']):
        domains.add('æ¨èç³»ç»Ÿ')
    if any(keyword in search_text for keyword in ['cv', 'computer-vision', 'opencv', 'image', 'yolo']):
        domains.add('CV')
    if any(keyword in search_text for keyword in ['web', 'frontend', 'react', 'vue', 'javascript']):
        domains.add('å‰ç«¯å¼€å‘')
    if any(keyword in search_text for keyword in ['gpt', 'llm', 'chatbot', 'llama']):
        domains.add('LLM')

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¢†åŸŸï¼Œè®¾ç½®é»˜è®¤å€¼
    if not domains:
        domains.add('æ•°æ®ç§‘å­¦')

    return list(domains)

def save_to_csv(members, output_file):
    """ä¿å­˜æ•°æ®åˆ° CSV æ–‡ä»¶"""
    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)

        # å†™å…¥è¡¨å¤´ï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µï¼‰
        writer.writerow([
            'id', 'name', 'github', 'domain', 'repositories',
            'public_repos', 'total_stars', 'followers', 'following',
            'avatar', 'bio', 'location', 'company'
        ])

        # å†™å…¥æ•°æ®
        for member in members:
            writer.writerow([
                member['id'],
                member['name'],
                member['github'],
                ';'.join(member['domains']),
                ';'.join(member.get('repositories', [])),
                member.get('public_repos', 0),
                member.get('total_stars', 0),
                member.get('followers', 0),
                member.get('following', 0),
                member.get('avatar', ''),
                member.get('bio', ''),
                member.get('location', ''),
                member.get('company', '')
            ])

def check_existing_data():
    """æ£€æŸ¥ç°æœ‰æ•°æ®æ–‡ä»¶"""
    return os.path.exists(CONFIG['OUTPUT_FILE'])

def backup_existing_data():
    """å¤‡ä»½ç°æœ‰æ•°æ®"""
    if os.path.exists(CONFIG['OUTPUT_FILE']):
        # å°†Pathå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¿›è¡Œæ“ä½œ
        output_file_str = str(CONFIG['OUTPUT_FILE'])
        backup_path = output_file_str.replace('.csv', f'.backup.{int(time.time())}.csv')
        import shutil
        shutil.copy2(CONFIG['OUTPUT_FILE'], backup_path)
        print(f"ğŸ“‹ å·²å¤‡ä»½ç°æœ‰æ•°æ®: {backup_path}")
        return backup_path
    return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®æ‹‰å–è„šæœ¬...")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {CONFIG['OUTPUT_FILE']}")
    print(f"ğŸ¢ ç»„ç»‡åç§°: {CONFIG['ORG_NAME']}")
    print(f"ğŸ”‘ Token çŠ¶æ€: {'å·²é…ç½®' if CONFIG['GITHUB_TOKEN'] else 'æœªé…ç½®'}")

    # å½“æœªå®‰è£… requests æ—¶ä¼˜é›…é™çº§ï¼šè‹¥æœ‰ç°æœ‰æ•°æ®åˆ™ç»§ç»­æ„å»ºï¼Œå¦åˆ™å¤±è´¥
    if requests is None:
        print("âš ï¸ ç¼ºå°‘ requests åº“ï¼Œè·³è¿‡ç½‘ç»œè¯·æ±‚ã€‚")
        if check_existing_data():
            print("ğŸ”„ ä½¿ç”¨ç°æœ‰æ•°æ®ç»§ç»­æ„å»º...")
            sys.exit(0)
        else:
            print("ğŸ’¥ æ²¡æœ‰ç°æœ‰æ•°æ®å¯ç”¨ï¼Œæ„å»ºå¤±è´¥")
            sys.exit(1)
    has_existing_data = check_existing_data()

    try:
        print("ğŸš€ å¼€å§‹æ‹‰å–æˆå‘˜æ•°æ®...")

        if has_existing_data:
            backup_existing_data()

        # ä»ç»„ç»‡ä»“åº“æ”¶é›†è´¡çŒ®è€…æ•°æ®
        contributors_data = collect_contributors_from_repos(CONFIG['ORG_NAME'])

        if not contributors_data:
            print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•è´¡çŒ®è€…æ•°æ®")

            if has_existing_data:
                print("âœ… ä¿æŒä½¿ç”¨ç°æœ‰æ•°æ®")
                return
            else:
                raise Exception("æ²¡æœ‰ç°æœ‰æ•°æ®å¯ç”¨ï¼Œä¸”æ— æ³•è·å–æ–°æ•°æ®")

        # å¤„ç†æ¯ä¸ªè´¡çŒ®è€…
        processed_members = []
        contributors_list = list(contributors_data.items())
        # å¤„ç†æ‰€æœ‰è´¡çŒ®è€…ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡é™åˆ¶ï¼‰
        max_contributors = min(len(contributors_list), int(os.getenv('MAX_CONTRIBUTORS', '200')))
        print(f"\nğŸ“Š å‡†å¤‡å¤„ç† {max_contributors} ä¸ªè´¡çŒ®è€…ï¼ˆæ€»å…± {len(contributors_list)} ä¸ªï¼‰")

        for i, (username, contrib_info) in enumerate(contributors_list[:max_contributors]):
            print(f"\nğŸ‘¤ å¤„ç†è´¡çŒ®è€… {i + 1}/{max_contributors}: {username}")
            print(f"  ğŸ“ˆ æ€»è´¡çŒ®: {contrib_info['total_contributions']} è¡Œ")
            print(f"  ğŸ“ å‚ä¸ä»“åº“: {len(contrib_info['repos'])} ä¸ª - {', '.join(contrib_info['repos'][:3])}{'...' if len(contrib_info['repos']) > 3 else ''}")

            try:
                # è·å–ç”¨æˆ·è¯¦ç»†ä¿¡æ¯
                user_details = get_user_details(username)
                if user_details:
                    print(f"  âœ“ è·å–ç”¨æˆ·è¯¦æƒ…: {user_details.get('name', username)}")
                else:
                    print(f"  âš ï¸ ç”¨æˆ·è¯¦æƒ…è·å–å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯")

                # è·å–ç”¨æˆ·ä¸ªäººä»“åº“ï¼ˆç”¨äºè®¡ç®— Stars ç­‰ç»Ÿè®¡ä¿¡æ¯ï¼‰
                user_repos = get_user_repos(username)
                print(f"  âœ“ è·å–ä¸ªäººä»“åº“: {len(user_repos)} ä¸ª")

                # è®¡ç®—ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯
                user_stats = calculate_user_stats(user_details, user_repos)
                print(f"  âœ“ ç»Ÿè®¡ä¿¡æ¯: {user_stats['public_repos']} ä»“åº“, {user_stats['total_stars']} Stars, {user_stats['followers']} å…³æ³¨è€…")

                # ä¸‹è½½å¹¶ç¼“å­˜å¤´åƒ
                avatar_url = user_details.get('avatar_url') if user_details else contrib_info['user_info'].get('avatar_url')
                local_avatar = download_avatar(avatar_url, username)

                # æ¨æ–­ç ”ç©¶æ–¹å‘ï¼ˆåŸºäºä»“åº“ topicsã€å‚ä¸çš„ä»“åº“åç§°å’Œç”¨æˆ·ç®€ä»‹ï¼‰
                user_bio = user_details.get('bio') if user_details else ''
                domains = infer_domains_from_repos(contrib_info['repos'], user_bio, user_repos)
                print(f"  âœ“ æ¨æ–­ç ”ç©¶æ–¹å‘: {', '.join(domains)}")

                processed_members.append({
                    'id': username,
                    'name': user_details.get('name') if user_details else username,
                    'github': contrib_info['user_info']['html_url'],
                    'domains': domains,
                    'repositories': contrib_info['repos'],  # å‚ä¸çš„ç»„ç»‡ä»“åº“åˆ—è¡¨
                    'public_repos': user_stats['public_repos'],  # ä¸ªäººå…¬å¼€ä»“åº“æ•°
                    'total_stars': user_stats['total_stars'],  # æ€» Stars æ•°
                    'followers': user_stats['followers'],  # å…³æ³¨è€…æ•°
                    'following': user_stats['following'],  # å…³æ³¨ä¸­æ•°
                    'avatar': local_avatar or avatar_url,  # å¤´åƒè·¯å¾„ï¼ˆä¼˜å…ˆæœ¬åœ°ç¼“å­˜ï¼‰
                    'bio': user_details.get('bio', '') if user_details else '',  # ä¸ªäººç®€ä»‹
                    'location': user_details.get('location', '') if user_details else '',  # ä½ç½®
                    'company': user_details.get('company', '') if user_details else ''  # å…¬å¸
                })

                # åŠ¨æ€å»¶è¿Ÿä»¥é¿å… API é€Ÿç‡é™åˆ¶
                delay = 0.1 if CONFIG['GITHUB_TOKEN'] else 0.3
                time.sleep(delay)

            except Exception as e:
                print(f"âš ï¸  å¤„ç†è´¡çŒ®è€… {username} æ—¶å‡ºé”™: {e}")
                print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
                import traceback
                print(f"  è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                # ç»§ç»­å¤„ç†å…¶ä»–è´¡çŒ®è€…

        if not processed_members:
            raise Exception("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æˆå‘˜æ•°æ®")

        # ä¿å­˜åˆ° CSV
        save_to_csv(processed_members, CONFIG['OUTPUT_FILE'])

        print(f"âœ… æˆåŠŸç”Ÿæˆ CSV æ–‡ä»¶: {CONFIG['OUTPUT_FILE']}")
        print(f"ğŸ“Š å¤„ç†äº† {len(processed_members)} ä¸ªæˆå‘˜")

    except Exception as e:
        print(f"âŒ æ•°æ®æ‹‰å–å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

        if has_existing_data:
            print("ğŸ”„ ä½¿ç”¨ç°æœ‰æ•°æ®ç»§ç»­æ„å»º...")
            print("ğŸ’¡ æç¤ºï¼šè®¾ç½® GITHUB_TOKEN ç¯å¢ƒå˜é‡å¯ä»¥é¿å… API é€Ÿç‡é™åˆ¶")
            sys.exit(0)  # ä¸ä¸­æ–­æ„å»ºæµç¨‹
        else:
            print("ğŸ’¥ æ²¡æœ‰ç°æœ‰æ•°æ®å¯ç”¨ï¼Œæ„å»ºå¤±è´¥")
            sys.exit(1)

if __name__ == '__main__':
    main()
